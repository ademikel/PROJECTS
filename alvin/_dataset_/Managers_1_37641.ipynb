{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3269279",
   "metadata": {
    "id": "e3269279"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger');\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9e37786d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e37786d",
    "outputId": "088ab8a1-1b21-4e7d-b61d-c3537cc76192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((373, 12), (558, 11), (10000, 12), (558, 14))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = pd.read_csv('Train.csv')\n",
    "Test = pd.read_csv('Test.csv')\n",
    "extra = pd.read_csv('extra_data.csv')\n",
    "sub = pd.read_csv('SampleSubmission.csv')\n",
    "random_seed = 12 # random seed for all computations\n",
    "Train.shape, Test.shape, extra.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a5db43c4-03b8-46fc-bd42-611ff6f839f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([Train, Test], sort = False).reset_index(drop = True)\n",
    "data = data.sort_values('PURCHASED_AT').reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6408e35b-1892-4663-b807-9fcaeb8b8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_isholiday(date):\n",
    "#     holiday_list = ['01-01-21', '14-02-21', '28-08-21', '14-04-21', '16-04-21', '21-04-21',\n",
    "#                     '01-05-21', '15-06-21', '07-09-21', '12-10-21', '02-11-21', '15-11-21', \n",
    "#                     '24-12-21', '25-12-21', '31-12-21',\n",
    "#                     '01-01-22', '14-02-22', '28-08-22', '14-04-22', '16-04-22', '21-04-22',\n",
    "#                     '01-05-22', '15-06-22', '07-09-22', '12-10-22', '02-11-22', '15-11-22', \n",
    "#                     '24-12-22', '25-12-22', '31-12-22']\n",
    "#     date = date.strftime(format='%d-%m-%y') \n",
    "#     if date in holiday_list:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "data['created_at_1'] = pd.to_datetime(data['MERCHANT_CATEGORIZED_AT'])\n",
    "data['created_at'] = pd.to_datetime(data['PURCHASED_AT'])\n",
    "# last_day = data.created_at.max()\n",
    "data['year'] = data['created_at'].dt.year\n",
    "data['month'] = data['created_at'].dt.month\n",
    "data['day'] = data['created_at'].dt.day\n",
    "# data['hour'] = data['created_at'].dt.hour\n",
    "# data['minute'] = data['created_at'].dt.minute\n",
    "# data['second'] = data['created_at'].dt.second\n",
    "# data['week'] = data['created_at'].dt.week\n",
    "# data['dayofweek'] = data['created_at'].dt.dayofweek\n",
    "# data['weekofyear'] = data['created_at'].dt.weekofyear\n",
    "# data['ismonthend'] = data['created_at'].dt.is_month_end\n",
    "# data['ismonthstart'] = data['created_at'].dt.is_month_start\n",
    "# data['quarter'] = data.created_at.dt.quarter\n",
    "# data['period'] = pd.cut(data['hour'], bins = [0, 4, 8, 12, 16, 20, 23], labels = ['Midnight', 'Early_Morning', 'Late_Morning', 'Afternoon', 'Evening', 'Night'])\n",
    "# data['year_month'] = data['year'].astype(str) + '-' + data['month'].astype(str)\n",
    "# data['month_day'] = data['month'].astype(str) + '-' + data['day'].astype(str)\n",
    "data['datediff'] = (data['created_at'] - data['created_at_1']).dt.total_seconds() / (60 * 60 * 24)\n",
    "# data['month_from_today'] = (12 * (last_day.year - data['created_at'].dt.year) + (last_day.month - data['created_at'].dt.month))\n",
    "# data['month_1'] = (last_day.day - data['created_at_1'].dt.day)//30\n",
    "# data['categorized_on_holiday'] = data['created_at'].apply(lambda date_obj: get_isholiday(date_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3ceea75-7890-4ee2-b127-39267e8b68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pc = data.copy()\n",
    "data_ex = pd.concat([Train, Test, extra], sort = False).reset_index(drop = True)\n",
    "def Agg_1(Feature):\n",
    "    for key in ('USER_ID','MERCHANT_NAME','IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY'):\n",
    "        data[f'{Feature}_{key}_Mean'] = data[key].map(dict(data_ex.groupby(key)[Feature].mean()))\n",
    "        # data[f'{Feature}_{key}_Quantile10'] = data[key].map(dict(data_ex.groupby(key)[Feature].quantile(0.10)))\n",
    "        data[f'{Feature}_{key}_Quantile25'] = data[key].map(dict(data_ex.groupby(key)[Feature].quantile(0.25)))\n",
    "        data[f'{Feature}_{key}_Quantile75'] = data[key].map(dict(data_ex.groupby(key)[Feature].quantile(0.75)))\n",
    "        # data[f'{Feature}_{key}_Quantile90'] = data[key].map(dict(data_ex.groupby(key)[Feature].quantile(0.90)))\n",
    "        data[f'{Feature}_{key}_Std'] = data[key].map(dict(data_ex.groupby(key)[Feature].std()))\n",
    "        # data[f'{Feature}_{key}_Min'] = data[key].map(dict(data_ex.groupby(key)[Feature].min()))\n",
    "        # data[f'{Feature}_{key}_Max'] = data[key].map(dict(data_ex.groupby(key)[Feature].max()))\n",
    "        data[f'{Feature}_{key}_Sum'] = data[key].map(dict(data_ex.groupby(key)[Feature].sum()))\n",
    "        # data[f'{Feature}_{key}_Range'] = data[key].map(dict(data_ex.groupby(key)[Feature].agg(np.ptp)))\n",
    "        # data[f'{Feature}_{key}_Kurt'] = data[key].map(dict(data_ex.groupby(key)[Feature].agg(pd.Series.kurt)))\n",
    "        data[f'{Feature}_{key}_Skew'] = data[key].map(dict(data_ex.groupby(key)[Feature].agg(pd.Series.skew)))\n",
    "        # data[f'{Feature}_{key}_Count'] = data[key].map(dict(data_ex.groupby(key)[Feature].count()))\n",
    "        data[f'{Feature}_{key}_NUnique'] = data[key].map(dict(data_ex.groupby(key)[Feature].nunique()))\n",
    "        # data[f'{Feature}_{key}_Mode'] = data[key].map(dict(data_ex.groupby(key)[Feature].apply(lambda x: x.value_counts().keys()[0])))\n",
    "        \n",
    "Agg_1('PURCHASE_VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d75bc860-12e9-404e-a3f3-c26e3f021e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns.difference(['MERCHANT_CATEGORIZED_AS']):\n",
    "    if data[col].isna().sum() > 0:\n",
    "        data[col].fillna(data[col].ffill().bfill(), inplace = True)\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c63c7007-35ab-4841-bb44-9783128f9341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1272b2ab-3808-48d8-8273-66b1994bffc5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dec = data_pc[['PURCHASE_VALUE_USER_ID_Mean',\n",
    "#  'PURCHASE_VALUE_USER_ID_Quantile10',\n",
    "#  'PURCHASE_VALUE_USER_ID_Quantile25',\n",
    "#  'PURCHASE_VALUE_USER_ID_Quantile75',\n",
    "#  'PURCHASE_VALUE_USER_ID_Quantile90',\n",
    "#  'PURCHASE_VALUE_USER_ID_Std',\n",
    "#  'PURCHASE_VALUE_USER_ID_Min',\n",
    "#  'PURCHASE_VALUE_USER_ID_Max',\n",
    "#  'PURCHASE_VALUE_USER_ID_Sum',\n",
    "#  'PURCHASE_VALUE_USER_ID_Range',\n",
    "#  'PURCHASE_VALUE_USER_ID_Kurt',\n",
    "#  'PURCHASE_VALUE_USER_ID_Skew',\n",
    "#  'PURCHASE_VALUE_USER_ID_Count',\n",
    "#  'PURCHASE_VALUE_USER_ID_NUnique',\n",
    "#  'PURCHASE_VALUE_USER_ID_Mode',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Mean',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Quantile10',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Quantile25',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Quantile75',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Quantile90',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Std',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Min',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Max',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Sum',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Range',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Kurt',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Skew',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Count',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_NUnique',\n",
    "#  'PURCHASE_VALUE_MERCHANT_NAME_Mode',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Mean',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Quantile10',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Quantile25',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Quantile75',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Quantile90',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Std',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Min',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Max',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Sum',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Range',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Kurt',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Skew',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Count',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_NUnique',\n",
    "#  'PURCHASE_VALUE_IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY_Mode',\n",
    "#  'PURCHASE_VALUE_period_Mean',\n",
    "#  'PURCHASE_VALUE_period_Quantile10',\n",
    "#  'PURCHASE_VALUE_period_Quantile25',\n",
    "#  'PURCHASE_VALUE_period_Quantile75',\n",
    "#  'PURCHASE_VALUE_period_Quantile90',\n",
    "#  'PURCHASE_VALUE_period_Std',\n",
    "#  'PURCHASE_VALUE_period_Min',\n",
    "#  'PURCHASE_VALUE_period_Max',\n",
    "#  'PURCHASE_VALUE_period_Sum',\n",
    "#  'PURCHASE_VALUE_period_Range',\n",
    "#  'PURCHASE_VALUE_period_Kurt',\n",
    "#  'PURCHASE_VALUE_period_Skew',\n",
    "#  'PURCHASE_VALUE_period_Count',\n",
    "#  'PURCHASE_VALUE_period_NUnique',\n",
    "#  'PURCHASE_VALUE_period_Mode']]\n",
    "\n",
    "# for col in data_dec.columns:\n",
    "#     data_dec[col].fillna(data_dec[col].ffill().bfill(), inplace = True)\n",
    "# data_dec.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "424eaeaa-a317-45a3-8c5f-cbf15a2d7054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # decomposition using PCA\n",
    "# pca = PCA(random_state = random_seed, n_components = 3)\n",
    "# data_pca = pca.fit_transform(data_dec)\n",
    "# data['PC_1'] = 0\n",
    "# # data['PC_2'] = 0\n",
    "# # data['PC_3'] = 0\n",
    "# data['PC_1'] = data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b91dbd13-ab71-4d9e-989c-9a3d486037ad",
   "metadata": {
    "id": "75Wr2-RjxgNQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.USER_GENDER.fillna('Female', inplace = True)\n",
    "# data.USER_AGE.fillna(25.0, inplace = True)\n",
    "# data.period.fillna('Afternoon', inplace = True)\n",
    "# values = data.mode().loc[0]\n",
    "# data = data.fillna(values)\n",
    "\n",
    "le = LabelEncoder()\n",
    "LE_cols = ['IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY', 'USER_ID', 'USER_GENDER']\n",
    "for le_col in LE_cols:\n",
    "    data[le_col] = le.fit_transform(data[le_col])\n",
    "\n",
    "data.drop(['Transaction_ID', 'created_at', 'created_at_1', 'MERCHANT_CATEGORIZED_AT', 'PURCHASED_AT', 'USER_AGE'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8b005261-ff85-4b10-9caf-647ab29da09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CouVec = CountVectorizer()\n",
    "CouVec.fit(data['MERCHANT_NAME'])\n",
    "\n",
    "data_words = pd.DataFrame(CouVec.transform(data['MERCHANT_NAME']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a056c4c7-efab-46e8-bbe3-030e52a6a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_part_of_speech(text):\n",
    "    text_splited = text.split(' ')\n",
    "    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n",
    "    text_splited = [s for s in text_splited if s]\n",
    "    pos_list = nltk.pos_tag(text_splited)\n",
    "    noun_count = len([w for w in pos_list if w[1] in ('NN','NNP','NNPS','NNS')])\n",
    "    adjective_count = len([w for w in pos_list if w[1] in ('JJ','JJR','JJS')])\n",
    "    verb_count = len([w for w in pos_list if w[1] in ('VB','VBD','VBG','VBN','VBP','VBZ')])\n",
    "    return[noun_count, adjective_count, verb_count]\n",
    "  \n",
    "data['Merchant_Name_Length'] = data['MERCHANT_NAME'].apply(lambda x : len(x))\n",
    "data['Num_Words'] = data['MERCHANT_NAME'].apply(lambda comment: len(comment.split()))\n",
    "data['Num_Unique_Words'] = data['MERCHANT_NAME'].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "data['Words_VS_Unique'] = data['Num_Unique_Words'] / data['Num_Words']\n",
    "data['num_punctuation'] = data['MERCHANT_NAME'].apply(lambda comment: sum(comment.count(w) for w in '\\'.,;:'))\n",
    "data['nouns'], data['adjectives'], data['verbs'] = zip(*data['MERCHANT_NAME'].apply(lambda comment: tag_part_of_speech(comment)))\n",
    "data['nouns_vs_length'] = data['nouns'] / data['Merchant_Name_Length']\n",
    "data['adjectives_vs_length'] = data['adjectives'] / data['Merchant_Name_Length']\n",
    "data['verbs_vs_length'] = data['verbs'] /data['Merchant_Name_Length']\n",
    "data['nouns_vs_words'] = data['nouns'] / data['Num_Words']\n",
    "data['adjectives_vs_words'] = data['adjectives'] / data['Num_Words']\n",
    "data['verbs_vs_words'] = data['verbs'] / data['Num_Words']\n",
    "data[\"count_words_title\"] = data[\"MERCHANT_NAME\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "data[\"mean_word_len\"] = data[\"MERCHANT_NAME\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "data['punct_percent']= data['num_punctuation']*100 / data['Num_Words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d50c76f-c067-418b-9f94-d70a460be5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=15, max_iter=100, random_state=42)\n",
    "LDA.fit(data_words)\n",
    "Topics = [f'Topic_{x}' for x in range(0,15)]\n",
    "data[Topics] = LDA.transform(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f48dde9-6092-4243-8bf5-bcd208207165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top_words = 10\n",
    "# topic_summaries = []\n",
    "\n",
    "# # get topics and topic terms\n",
    "# topic_word = LDA.components_ \n",
    "# vocab = CouVec.get_feature_names()\n",
    "\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "#     topic_summaries.append(' '.join(topic_words))\n",
    "#     print('Topic {}: {}'.format(i, ' | '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc96c87a-8a27-44cb-986c-ec0b748d7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a, b in Train.MERCHANT_NAME.groupby([Train.MERCHANT_CATEGORIZED_AS]):\n",
    "#     print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a119fda6-389c-4128-a48f-5f9b74116f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MERCHANT_NAME'] = le.fit_transform(data['MERCHANT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56f2b8f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56f2b8f2",
    "outputId": "415eeb13-ab52-4163-ab7a-873701862bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (373, 65) (558, 64)\n"
     ]
    }
   ],
   "source": [
    "# separating data into train and test\n",
    "train = data[data.MERCHANT_CATEGORIZED_AS.notnull()].reset_index(drop = True)\n",
    "test = data[data.MERCHANT_CATEGORIZED_AS.isna()].reset_index(drop = True)\n",
    "test.drop('MERCHANT_CATEGORIZED_AS', axis = 1, inplace = True)\n",
    "print('shape', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41defaa5-0802-4330-befb-832e3075c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MERCHANT_CATEGORIZED_AS'] = le.fit_transform(train['MERCHANT_CATEGORIZED_AS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1eed88c-a818-4e04-8529-98f6024db713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15, 15))\n",
    "# sns.heatmap(data.corr(), cmap = 'coolwarm', square = True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "22ac489d-c184-4b9c-97e2-d8f641e5208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicated\n",
    "cols = train.columns\n",
    "dup = []\n",
    "for feat_1 in cols:\n",
    "    if (feat_1 in dup):\n",
    "        continue\n",
    "    for feat_2 in cols.drop(feat_1):\n",
    "        if (feat_2 in dup):\n",
    "            continue\n",
    "        if (train[feat_1].equals(train[feat_2])):\n",
    "            train.drop(feat_2,inplace=True,axis=1)\n",
    "            test.drop(feat_2,inplace=True,axis=1)\n",
    "            dup.append(feat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d06a2d37-759d-4d88-b061-da2d0484f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant\n",
    "for feat in test.columns:\n",
    "    if ((len(train[feat].value_counts().keys()) == 1) | (len(test[feat].value_counts().keys()) == 1)):\n",
    "        train.drop(feat,inplace=True,axis=1)\n",
    "        test.drop(feat,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "151d60a2-0620-46e5-9611-d184276646cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {'iterations' : 1300, 'learning_rate' : 0.09, 'depth' : 5, 'reg_lambda' : 17.56889442852513, 'verbose' : 0}\n",
    "cb = CatBoostClassifier(**cb_params, random_state = random_seed)\n",
    "\n",
    "rf_params = {'n_estimators': 4600, 'max_depth': 12, 'min_samples_split': 3,'min_samples_leaf': 1, 'max_features': 0.25}\n",
    "rf_ = RandomForestClassifier(**rf_params, n_jobs= -1, random_state = random_seed)\n",
    "\n",
    "xgb_ = XGBClassifier(random_state = random_seed, objective = 'multi:softprob', num_class = 13, learning_rate = 0.05976,  max_depth = 6, \n",
    "                    subsample = 0.5, colsample_bytree = 0.5, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3e77bbc7-0111-4712-9f72-231d2682986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "1.4797753137656173\n",
      "1.5759520525947504\n",
      "\n",
      "Mean: 1.527863683180184 \n",
      "STD:  0.04808836941456651\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "X_split = train.drop('MERCHANT_CATEGORIZED_AS',axis = 1).values\n",
    "y_split = train['MERCHANT_CATEGORIZED_AS'].values\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in StratifiedKFold(n_splits = 2, shuffle = True, random_state = random_seed).split(X_split, y_split):\n",
    "    X_Train, X_Test = X_split[train_index], X_split[test_index]\n",
    "    y_Train, y_Test = y_split[train_index], y_split[test_index]\n",
    "    cb.fit(X_Train, y_Train)\n",
    "    rf_.fit(X_Train, y_Train)\n",
    "    xgb_.fit(X_Train, y_Train)\n",
    "\n",
    "    y_Pred = 0.15 * xgb_.predict_proba(X_Test) + 0.45 * cb.predict_proba(X_Test) + 0.4 * rf_.predict_proba(X_Test)\n",
    "    scores.append(log_loss(y_Test, y_Pred))\n",
    "    print(log_loss(y_Test, y_Pred))\n",
    "\n",
    "print(\"\\nMean:\",np.mean(scores),\"\\nSTD: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c6dbc6f1-0f30-40aa-bf28-8a9a483a2225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "1.4638703907315687\n",
      "1.6101444209907403\n",
      "\n",
      "Mean: 1.5370074058611545 \n",
      "STD:  0.07313701512958581\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "X_split = train.drop('MERCHANT_CATEGORIZED_AS',axis=1).values\n",
    "y_split = train['MERCHANT_CATEGORIZED_AS'].values\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in KFold(n_splits = 2, shuffle = True, random_state = random_seed).split(X_split, y_split):\n",
    "    X_Train, X_Test = X_split[train_index], X_split[test_index]\n",
    "    y_Train, y_Test = y_split[train_index], y_split[test_index]\n",
    "    cb.fit(X_Train, y_Train)\n",
    "    rf_.fit(X_Train, y_Train)\n",
    "    xgb_.fit(X_Train, y_Train)\n",
    "\n",
    "    y_Pred = 0.2 * xgb_.predict_proba(X_Test) + 0.47 * cb.predict_proba(X_Test) + 0.33 * rf_.predict_proba(X_Test)\n",
    "    scores.append(log_loss(y_Test, y_Pred))\n",
    "    print(scores[-1])\n",
    "\n",
    "print(\"\\nMean:\",np.mean(scores),\"\\nSTD: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d2825a45",
   "metadata": {
    "id": "d2825a45"
   },
   "outputs": [],
   "source": [
    "# use_feat = ['MERCHANT_NAME', 'PURCHASE_VALUE', 'IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY', 'USER_HOUSEHOLD', 'USER_INCOME', 'delta_days', 'year', 'month', 'cluster', 'merchant_dec']\n",
    "# X_, y_ = train[use_feat], train[\"MERCHANT_CATEGORIZED_AS\"]\n",
    "X_, y_ = train.drop(\"MERCHANT_CATEGORIZED_AS\", axis = 1), train[\"MERCHANT_CATEGORIZED_AS\"]\n",
    "X, y = SMOTE(k_neighbors = 1, random_state = 1).fit_resample(X_, y_)\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = random_seed, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "82b78716-b300-4e2b-af6f-d189c78b3097",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 =====\n",
      "0.5855852298197676\n",
      "===== Fold 2 =====\n",
      "0.42631013867016726\n",
      "===== Fold 3 =====\n",
      "0.4829029132561286\n",
      "===== Fold 4 =====\n",
      "0.38934389371334926\n",
      "===== Fold 5 =====\n",
      "0.5328382556507935\n",
      "cat_score : 0.4833960862220413\n"
     ]
    }
   ],
   "source": [
    "cat_scores = []\n",
    "for fold,(tr_in,te_in) in enumerate(skf.split(X, y)):\n",
    "    print(\"===== Fold {fold} =====\".format(fold = fold + 1))\n",
    "    X_train, X_test = X.iloc[tr_in], X.iloc[te_in]\n",
    "    y_train, y_test = y.iloc[tr_in], y.iloc[te_in]\n",
    "    cat = CatBoostClassifier(iterations = 1300, learning_rate = 0.09, depth = 6, reg_lambda = 17.56889442852513, verbose = 0, random_state = random_seed)\n",
    "    cat.fit(X_train, y_train, eval_set = [(X_train, y_train),(X_test, y_test)], early_stopping_rounds = 500, use_best_model = True)\n",
    "    loss = log_loss(y_test, cat.predict_proba(X_test))\n",
    "    cat_scores.append(loss)\n",
    "    print(loss)\n",
    "\n",
    "print('cat_score : ' + str(np.mean(cat_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b52d92fc-8589-4d06-8e6c-e5bb3f67f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 =====\n",
      "0.6200538923137134\n",
      "===== Fold 2 =====\n",
      "0.4726855188457359\n",
      "===== Fold 3 =====\n",
      "0.48842859128751726\n",
      "===== Fold 4 =====\n",
      "0.4310253878233724\n",
      "===== Fold 5 =====\n",
      "0.5877848570619839\n",
      "\n",
      "rf_score 0.5199956494664646\n"
     ]
    }
   ],
   "source": [
    "rf_scores = []\n",
    "for fold,(tr_in,te_in) in enumerate(skf.split(X, y)):\n",
    "    print(\"===== Fold {fold} =====\".format(fold = fold + 1))\n",
    "    X_train, X_test = X.iloc[tr_in], X.iloc[te_in]\n",
    "    y_train, y_test = y.iloc[tr_in], y.iloc[te_in]\n",
    "    rf = RandomForestClassifier(n_estimators = 4600, max_depth = 12, min_samples_split = 3, min_samples_leaf = 1, max_features = 0.25, n_jobs= -1, random_state = random_seed)\n",
    "    rf.fit(X_train, y_train)\n",
    "    loss = log_loss(y_test, rf.predict_proba(X_test))\n",
    "    rf_scores.append(loss)\n",
    "    print(loss)\n",
    "\n",
    "print('\\nrf_score ' + str(np.mean(rf_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1dd8e61d-cd72-4320-92aa-fb5202c34482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 =====\n",
      "0.6350299193950489\n",
      "===== Fold 2 =====\n",
      "0.4776210954385291\n",
      "===== Fold 3 =====\n",
      "0.481356908966388\n",
      "===== Fold 4 =====\n",
      "0.4177657750715029\n",
      "===== Fold 5 =====\n",
      "0.5601506697262941\n",
      "\n",
      "xgb_score 0.5143848737195527\n"
     ]
    }
   ],
   "source": [
    "xgb_scores = []\n",
    "for fold,(tr_in,te_in) in enumerate(skf.split(X, y)):\n",
    "    print(\"===== Fold {fold} =====\".format(fold = fold + 1))\n",
    "    X_train, X_test = X.iloc[tr_in], X.iloc[te_in]\n",
    "    y_train, y_test = y[tr_in], y[te_in]\n",
    "    xgb = XGBClassifier(random_state = random_seed, objective = 'multi:softprob', num_class = 13, learning_rate = 0.05976,  max_depth = 6, \n",
    "                        subsample = 0.5, colsample_bytree = 0.5, eval_metric='mlogloss')\n",
    "    xgb.fit(X_train, y_train)\n",
    "    loss = log_loss(y_test, xgb.predict_proba(X_test))\n",
    "    xgb_scores.append(loss)\n",
    "    print(loss)\n",
    "\n",
    "print('\\nxgb_score ' + str(np.mean(xgb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cacb9a0c-9c9e-4d71-a425-c2b55585ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 =====\n",
      "0.591244023824\n",
      "===== Fold 2 =====\n",
      "0.44579967223701605\n",
      "===== Fold 3 =====\n",
      "0.47114409414467917\n",
      "===== Fold 4 =====\n",
      "0.40003743660797286\n",
      "===== Fold 5 =====\n",
      "0.5409934702176725\n",
      "\n",
      "vcl_score 0.48984373940626813\n"
     ]
    }
   ],
   "source": [
    "vcl_scores = []\n",
    "for fold,(tr_in,te_in) in enumerate(skf.split(X, y)):\n",
    "    print(\"===== Fold {fold} =====\".format(fold = fold + 1))\n",
    "    X_train, X_test = X.iloc[tr_in], X.iloc[te_in]\n",
    "    y_train, y_test = y.iloc[tr_in], y.iloc[te_in]\n",
    "    vcl = VotingClassifier([('cat', cat), ('rf', rf), ('xgb', xgb)], weights = (1, 1, 1), voting = 'soft')\n",
    "    vcl.fit(X_train, y_train)\n",
    "    loss = log_loss(y_test, vcl.predict_proba(X_test))\n",
    "    vcl_scores.append(loss)\n",
    "    print(loss)\n",
    "\n",
    "print('\\nvcl_score ' + str(np.mean(vcl_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "076d92de-04e6-4519-b015-bd0bdeac93a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_imp_df = pd.DataFrame(lgb.feature_importances_, columns = ['Importance'])\n",
    "# feat_imp_df['Features'] = X_.columns\n",
    "# feat_imp_df.sort_values(by = 'Importance', ascending = False)\n",
    "# # print(feat_imp_df[feat_imp_df.Importance < 1].Features.to_list(), end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "iUQ4d5Ovd-b2",
   "metadata": {
    "id": "iUQ4d5Ovd-b2"
   },
   "outputs": [],
   "source": [
    "def predict_and_submit(test_, filename):\n",
    "    d = {\"Transaction_ID\": sub[\"Transaction_ID\"], 'Bills & Fees':test_[:, 0], 'Data & WiFi':test_[:, 1], 'Education':test_[:, 2], 'Emergency fund':test_[:, 3],'Family & Friends':test_[:, 4],'Going out':test_[:, 5],'Groceries':test_[:, 6],\\\n",
    "        'Health':test_[:, 7],'Loan Repayment':test_[:, 8],'Miscellaneous':test_[:, 9],'Rent / Mortgage':test_[:, 10],'Shopping':test_[:, 11],'Transport & Fuel':test_[:, 12]}\n",
    "    df_ = pd.DataFrame(data=d)\n",
    "    df_ = df_[[\"Transaction_ID\", 'Bills & Fees','Data & WiFi','Education','Emergency fund','Family & Friends','Going out','Groceries','Health','Loan Repayment','Miscellaneous','Rent / Mortgage','Shopping','Transport & Fuel']]\n",
    "    df_.to_csv(f'{filename}.csv', index = False)\n",
    "    return df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ad8d7892-c901-469c-bfb7-e3ddf6bbd892",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f852c3df",
    "outputId": "513ec7d2-f5d7-4560-87d7-58da0d49e58f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_a = cat.predict_proba(test)\n",
    "y_b = rf.predict_proba(test)\n",
    "y_c = xgb.predict_proba(test)\n",
    "y_d = vcl.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "44f12f59-5b0f-4b61-91d9-bc3e3ccf7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_a * 0.3 + y_b * 0.2 + y_c * 0.1 + y_d * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e133a766-730e-4579-a682-24abb7293167",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f852c3df",
    "outputId": "513ec7d2-f5d7-4560-87d7-58da0d49e58f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 14)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_and_submit(y_e, 'Alvin_vcl_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0d5be7a7-82dc-41f2-8ca6-7f538c7a453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bills & Fees', 'Data & WiFi', 'Education', 'Emergency fund',\n",
       "       'Family & Friends', 'Going out', 'Groceries', 'Health',\n",
       "       'Loan Repayment', 'Miscellaneous', 'Rent / Mortgage', 'Shopping',\n",
       "       'Transport & Fuel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_Values = Train['MERCHANT_CATEGORIZED_AS'].value_counts().keys().sort_values()\n",
    "Target_Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "19eca9c2-4c6d-4669-8eeb-15c024d0fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcl_ = VotingClassifier([('cb', cb), ('rf_', rf_), ('xgb_', xgb_)], weights = (1, 1, 1), voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b9ccf679-65c0-4058-8b19-b74f7d20a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;cb&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000021462E60B80&gt;),\n",
       "                             (&#x27;rf_&#x27;,\n",
       "                              RandomForestClassifier(max_depth=12,\n",
       "                                                     max_features=0.25,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     n_estimators=4600,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=12)),\n",
       "                             (&#x27;xgb_&#x27;,\n",
       "                              XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=&#x27;&#x27;,\n",
       "                                            learning_rate=0.05976, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=&#x27;()&#x27;,\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_class=13, num_parallel_tree=1,\n",
       "                                            objective=&#x27;multi:softprob&#x27;,\n",
       "                                            predictor=&#x27;auto&#x27;, random_state=12, ...))],\n",
       "                 voting=&#x27;soft&#x27;, weights=(1, 1, 1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;cb&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000021462E60B80&gt;),\n",
       "                             (&#x27;rf_&#x27;,\n",
       "                              RandomForestClassifier(max_depth=12,\n",
       "                                                     max_features=0.25,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     n_estimators=4600,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=12)),\n",
       "                             (&#x27;xgb_&#x27;,\n",
       "                              XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=&#x27;&#x27;,\n",
       "                                            learning_rate=0.05976, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=&#x27;()&#x27;,\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_class=13, num_parallel_tree=1,\n",
       "                                            objective=&#x27;multi:softprob&#x27;,\n",
       "                                            predictor=&#x27;auto&#x27;, random_state=12, ...))],\n",
       "                 voting=&#x27;soft&#x27;, weights=(1, 1, 1))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000021462E60B80&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf_</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=12, max_features=0.25, min_samples_split=3,\n",
       "                       n_estimators=4600, n_jobs=-1, random_state=12)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb_</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.05976, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=100, n_jobs=0, num_class=13, num_parallel_tree=1,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=12, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('cb',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x0000021462E60B80>),\n",
       "                             ('rf_',\n",
       "                              RandomForestClassifier(max_depth=12,\n",
       "                                                     max_features=0.25,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     n_estimators=4600,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=12)),\n",
       "                             ('xgb_',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.05976, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_class=13, num_parallel_tree=1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            predictor='auto', random_state=12, ...))],\n",
       "                 voting='soft', weights=(1, 1, 1))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop('MERCHANT_CATEGORIZED_AS',axis=1)\n",
    "y = train['MERCHANT_CATEGORIZED_AS']\n",
    "        \n",
    "cb.fit(X, y)\n",
    "rf_.fit(X, y)\n",
    "xgb_.fit(X, y)\n",
    "vcl_.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "099de0a2-7d59-4c1f-90dc-4ccf4b145f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = vcl_.predict_proba(test)\n",
    "ID = sub['Transaction_ID']\n",
    "submission = pd.DataFrame({\"Id\": ID})\n",
    "Predictions = pd.DataFrame(Predictions, index = test.index, columns = Target_Values)\n",
    "submission = pd.concat([submission.reset_index(drop=True),Predictions.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1da61140-ff82-4ed6-9a49-884ecb592f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('aisquad0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b745ea6-31b1-47e4-b28e-77803b3ec3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Managers_1_37641.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
