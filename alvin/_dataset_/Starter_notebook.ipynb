{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvKRBlqreh9N"
   },
   "source": [
    "# AlvinApp Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNl4Kvk3d_s3"
   },
   "source": [
    "This is a simple starter notebook to get started with the AvinApp Competition on Zindi.\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "*   Loading the data\n",
    "*   Simple Exploratory Data Analysis and an example of feature engineering\n",
    "*   Data preprocessing and data wrangling\n",
    "*   Creating a simple model\n",
    "*   Making a submission\n",
    "*   Some tips for improving your score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYdpBYYceneg"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "06kkNxjIdgSW"
   },
   "outputs": [],
   "source": [
    "# Dataframe and Plotting libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning libraries\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# from google.colab import files\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8AhJ0cKer7b"
   },
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n9KORySPiN1r"
   },
   "outputs": [],
   "source": [
    "# Testing path\n",
    "# path = '/content/drive/MyDrive/Colab Notebooks/alvinapp/'\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "aPn2dmoMexCU"
   },
   "outputs": [],
   "source": [
    "# Load the files into a Pandas Dataframe\n",
    "train = pd.read_csv(path+'Train.csv')\n",
    "test = pd.read_csv(path+'Test.csv')\n",
    "sub = pd.read_csv(path+'SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSj_1Qz7ezsw",
    "outputId": "46425755-d8be-4bab-9d03-4e491eb3162a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape : (373, 12)\n",
      "Test data shape : (558, 11)\n"
     ]
    }
   ],
   "source": [
    "# Let’s observe the shape of our datasets.\n",
    "print('Train data shape :', train.shape)\n",
    "print('Test data shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"USER_GENDER\"] = train[\"USER_GENDER\"].apply(lambda x: \"Gay\" if pd.isna(x) else x)\n",
    "test[\"USER_GENDER\"] = test[\"USER_GENDER\"].apply(lambda x: \"Gay\" if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ilUVxzfkrK9u"
   },
   "outputs": [],
   "source": [
    "train.drop(['USER_AGE'], 1, inplace = True)\n",
    "test.drop(['USER_AGE'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"train\"] = 1\n",
    "test[\"train\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "m2IvLQ6Yregx"
   },
   "outputs": [],
   "source": [
    "# all_data = pd.get_dummies(all_data, prefix_sep=\"_\", columns=['MERCHANT_NAME'])\n",
    "freq_coll = ['MERCHANT_NAME', 'USER_ID']\n",
    "for col in freq_coll:\n",
    "    all_data[col] = all_data[col].map(all_data.groupby(col).size() / len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "LE_cols = ['USER_ID', 'IS_PURCHASE_PAID_VIA_MPESA_SEND_MONEY', 'USER_HOUSEHOLD', 'USER_GENDER']\n",
    "for le_col in LE_cols:\n",
    "    all_data[le_col] = le.fit_transform(all_data[le_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0RrIAKorrCd"
   },
   "source": [
    "Let's see how this affected the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[all_data[\"train\"] == 1]\n",
    "test = all_data[all_data[\"train\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur_WN81srqMF",
    "outputId": "af2e378c-1c37-485b-d201-bcdccde3b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (373, 12)\n",
      "Test:  (558, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train.shape)\n",
    "print(\"Test: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-hQBD7R1gF1"
   },
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6Smz5ogrxFt"
   },
   "source": [
    "We can also drop unnecessary categorical columns as we're currently not interested in when the purchases were made or when they were categorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ySpFfwxJr4D7"
   },
   "outputs": [],
   "source": [
    "train = train.drop(['MERCHANT_CATEGORIZED_AT','PURCHASED_AT', 'Transaction_ID', \"train\"], axis=1)\n",
    "test = test.drop(['MERCHANT_CATEGORIZED_AT','PURCHASED_AT', \"train\", \"MERCHANT_CATEGORIZED_AS\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "v0Y0uKWguZ9n"
   },
   "outputs": [],
   "source": [
    "# Separate the features from the target in the training data\n",
    "X = train.drop([\"MERCHANT_CATEGORIZED_AS\"], axis=1)\n",
    "y = train[\"MERCHANT_CATEGORIZED_AS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXwzW_sq1Arr",
    "outputId": "76cb1f56-1c85-46d5-a3c0-6f41f0a6d8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "clVOI_t16J1k"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=101, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 11)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nunique(), y_val.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "id": "RZNyCOCf26Gd",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 11, 13. Please provide the true labels explicitly through the labels argument. Classes found in y_true: ['Bills & Fees' 'Data & WiFi' 'Emergency fund' 'Family & Friends'\n 'Going out' 'Groceries' 'Health' 'Loan Repayment' 'Miscellaneous'\n 'Shopping' 'Transport & Fuel']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCURACY OF THE MODEL: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mlog_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2439\u001b[0m, in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lb\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m   2438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2439\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2440\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred contain different number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2441\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Please provide the true \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels explicitly through the labels argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses found in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2444\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true: \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2445\u001b[0m                 transformed_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], lb\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   2446\u001b[0m             )\n\u001b[0;32m   2447\u001b[0m         )\n\u001b[0;32m   2448\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2449\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes in labels is different \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2451\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom that in y_pred. Classes found in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2452\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(lb\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m   2453\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 11, 13. Please provide the true labels explicitly through the labels argument. Classes found in y_true: ['Bills & Fees' 'Data & WiFi' 'Emergency fund' 'Family & Friends'\n 'Going out' 'Groceries' 'Health' 'Loan Repayment' 'Miscellaneous'\n 'Shopping' 'Transport & Fuel']"
     ]
    }
   ],
   "source": [
    "# clf = RandomForestClassifier(random_state = 1)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict_proba(X_val)\n",
    "# print(\"ACCURACY OF THE MODEL: \", log_loss(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.5526315789473685\n"
     ]
    }
   ],
   "source": [
    "cb_model_ = CatBoostClassifier(l2_leaf_reg = 9.441413522475084, depth = 5, bootstrap_type = 'MVS', learning_rate = 0.01712339213540557, n_estimators = 2950,\n",
    "                               leaf_estimation_iterations = 1, random_strength = 0.18095032711212016, loss_function = 'MultiClass', verbose = 0, random_state = 1)\n",
    "cb_model_.fit(X_train, y_train)\n",
    "y_pred = cb_model_.predict(X_val)\n",
    "print(\"ACCURACY OF THE MODEL: \", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Data & WiFi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m cb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cb_model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mlog_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2394\u001b[0m, in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_loss\u001b[39m(\n\u001b[0;32m   2325\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-15\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2326\u001b[0m ):\n\u001b[0;32m   2327\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Log loss, aka logistic loss or cross-entropy loss.\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m \n\u001b[0;32m   2329\u001b[0m \u001b[38;5;124;03m    This is the loss function used in (multinomial) logistic regression\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2392\u001b[0m \u001b[38;5;124;03m    p. 209.\u001b[39;00m\n\u001b[0;32m   2393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2394\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2395\u001b[0m     check_consistent_length(y_pred, y_true, sample_weight)\n\u001b[0;32m   2397\u001b[0m     lb \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Data & WiFi'"
     ]
    }
   ],
   "source": [
    "# from catboost import Pool, CatBoostClassifier\n",
    "# cb_model = CatBoostClassifier(l2_leaf_reg = 9.441413522475084, depth = 7, bootstrap_type = 'Bayesian', learning_rate = 0.01772339213540557, n_estimators = 3167,\n",
    "#                                                  leaf_estimation_iterations = 1, random_strength = 0.17095032711212016, loss_function = 'MultiClass', verbose = 0, random_state = 101)\n",
    "# cb_model.fit(X_train, y_train)\n",
    "# y_pred = cb_model.predict(X_val)\n",
    "# log_loss(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJnV9lsd2-s-"
   },
   "source": [
    "### 5. Making the first submission\n",
    "\n",
    "Let’s see how the model performs on the competition test data set provided and how we rank on the competition leaderboard.\n",
    "\n",
    "First we make predictions on the competition test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "LoH4zhJb3EV4"
   },
   "outputs": [],
   "source": [
    "# Get the predicted result for the test Data\n",
    "predictions = clf.predict_proba(test.drop(\"Transaction_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_submit(test_, filename):\n",
    "    d = {\"Transaction_ID\": sub[\"Transaction_ID\"], 'Bills & Fees':test_[:, 0], 'Data & WiFi':test_[:, 1], 'Education':test_[:, 2], 'Emergency fund':test_[:, 3],'Family & Friends':test_[:, 4],'Going out':test_[:, 5],'Groceries':test_[:, 6],\\\n",
    "        'Health':test_[:, 7],'Loan Repayment':test_[:, 8],'Miscellaneous':test_[:, 9],'Rent / Mortgage':test_[:, 10],'Shopping':test_[:, 11],'Transport & Fuel':test_[:, 12]}\n",
    "    df_ = pd.DataFrame(data=d)\n",
    "    df_ = df_[[\"Transaction_ID\", 'Bills & Fees','Data & WiFi','Education','Emergency fund','Family & Friends','Going out','Groceries','Health','Loan Repayment','Miscellaneous','Rent / Mortgage','Shopping','Transport & Fuel']]\n",
    "    df_.to_csv(f'{filename}.csv', index = False)\n",
    "    return df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 14)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_and_submit(predictions, 'Manager_')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Alvinapp competition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
