{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "XTJoUX3UZh5u"
      },
      "id": "XTJoUX3UZh5u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Google_Drive_logo.png/600px-Google_Drive_logo.png' height=\"150\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Mount GDrive to /content/drive</h3></center><br>\n",
        "MODE = \"MOUNT\" #@param [\"MOUNT\", \"UNMOUNT\"]\n",
        "#Mount your Gdrive! \n",
        "from google.colab import drive\n",
        "drive.mount._DEBUG = False\n",
        "if MODE == \"MOUNT\":\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "elif MODE == \"UNMOUNT\":\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "  except ValueError:\n",
        "    pass\n",
        "  get_ipython().system_raw(\"rm -rf /root/.config/Google/DriveFS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "pKafspxrWUdV",
        "outputId": "e797f39a-614c-47e9-ce21-2497dceb9b95"
      },
      "id": "pKafspxrWUdV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "3f5e6a33-cdf1-4837-a7e5-5d7c2cc8419c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f5e6a33-cdf1-4837-a7e5-5d7c2cc8419c",
        "outputId": "980035fc-cba5-44d9-e708-74fb67cef375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger');\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "path = '/content/drive/MyDrive/COLAB/DATASETS/MAX_NG Data'\n",
        "train = pd.read_csv(f'{path}/train.csv')\n",
        "test = pd.read_csv(f'{path}/test.csv')\n",
        "sub = pd.read_csv(f'{path}/sample_submission.csv')\n",
        "random_seed = 2001 # random seed for all computations"
      ],
      "metadata": {
        "id": "LsemBu_5Witw"
      },
      "id": "LsemBu_5Witw",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "cd14cd04-1b3a-4c71-854c-79619e887b62",
      "metadata": {
        "id": "cd14cd04-1b3a-4c71-854c-79619e887b62"
      },
      "outputs": [],
      "source": [
        "# test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c91c9d6c-fbed-4789-84d6-d55af7b07afa",
      "metadata": {
        "id": "c91c9d6c-fbed-4789-84d6-d55af7b07afa"
      },
      "outputs": [],
      "source": [
        "# train[train.stage_status.isna() == False].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "169de9ce-2fd3-47d7-b8cd-c28e35ce55ca",
      "metadata": {
        "id": "169de9ce-2fd3-47d7-b8cd-c28e35ce55ca"
      },
      "outputs": [],
      "source": [
        "feat_1 = ['stage_status', 'agent_id']\n",
        "feat_2 = ['subscriber_age', 'gender', 'city']\n",
        "for data in (train, test):\n",
        "    for feat in feat_1:\n",
        "        data[feat] = data[feat].bfill().ffill()\n",
        "    for feat_ in feat_2:\n",
        "        data[feat_] = data[feat_].fillna(data[feat_].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8158ebd6-faaa-437e-bbad-f08e250196df",
      "metadata": {
        "id": "8158ebd6-faaa-437e-bbad-f08e250196df"
      },
      "outputs": [],
      "source": [
        "# sns.set_style(\"white\") \n",
        "# sns.countplot( y='label', data=train, palette=\"Set1\")\n",
        "# train[train.label == 'Backlkog']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "04f75fa6-80ee-4178-bdce-df7489e35e28",
      "metadata": {
        "id": "04f75fa6-80ee-4178-bdce-df7489e35e28"
      },
      "outputs": [],
      "source": [
        "# num_feats = list(train.select_dtypes(include=['int64', 'float64', 'int32']).columns)\n",
        "# train[num_feats].hist(figsize=(20,15));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "30af77bb-8cd7-4765-8dc5-54bbf272172e",
      "metadata": {
        "id": "30af77bb-8cd7-4765-8dc5-54bbf272172e"
      },
      "outputs": [],
      "source": [
        "# test.subscriber_age > 90\n",
        "# train = train.drop(train[train.subscriber_age > 90].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "44cce122-fe28-4514-a8d9-28e12b0366fb",
      "metadata": {
        "id": "44cce122-fe28-4514-a8d9-28e12b0366fb"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(y = 'label', data = train, hue = \"city\", palette=\"Set1\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "7d45c43b-1b25-4237-8ab1-5a17395298c6",
      "metadata": {
        "id": "7d45c43b-1b25-4237-8ab1-5a17395298c6"
      },
      "outputs": [],
      "source": [
        "# train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ccf17ee5-07d5-4da3-98f3-4fde54eb23dd",
      "metadata": {
        "id": "ccf17ee5-07d5-4da3-98f3-4fde54eb23dd"
      },
      "outputs": [],
      "source": [
        "# train[train.city == 'ibadan']\n",
        "train.city = train.city.str.replace('ibadan', 'Ibadan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "2d394526-e03f-4a06-a2b9-b22bca5e7bba",
      "metadata": {
        "id": "2d394526-e03f-4a06-a2b9-b22bca5e7bba"
      },
      "outputs": [],
      "source": [
        "train = train.sort_values('date_time').reset_index(drop = True)\n",
        "test = test.sort_values('date_time').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f466b800-44e6-4604-9aa4-d21a098f1664",
      "metadata": {
        "id": "f466b800-44e6-4604-9aa4-d21a098f1664"
      },
      "outputs": [],
      "source": [
        "for data in (train, test):\n",
        "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
        "    data['year'] = data.date_time.dt.year\n",
        "    data['month'] = data.date_time.dt.month\n",
        "    data['day'] = data.date_time.dt.day\n",
        "    # data['hour'] = data.date_time.dt.hour\n",
        "    # data['minute'] = data.date_time.dt.minute\n",
        "    # data['second'] = data.date_time.dt.second\n",
        "    data['year_month_day'] = data.year.astype(str) + '_' + data.month.astype(str)  + '_' + data.day.astype(str)\n",
        "    data['month_day'] = data.month.astype(str)  + '_' + data.day.astype(str)\n",
        "    data.drop('date_time', axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e680233f-f389-4202-b90d-4b690aab4a3a",
      "metadata": {
        "id": "e680233f-f389-4202-b90d-4b690aab4a3a"
      },
      "outputs": [],
      "source": [
        "ID = test['ID']\n",
        "test.drop(['ID', 'gender'],inplace=True,axis=1)\n",
        "train.drop(['ID', 'gender'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.agent_id.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e0U2Ktd98l",
        "outputId": "14a8b170-a1f5-40cd-97fd-7d48f4c4e14b"
      },
      "id": "64e0U2Ktd98l",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c82271a1-0f92-4bfd-bfb0-d7d555db8355",
      "metadata": {
        "id": "c82271a1-0f92-4bfd-bfb0-d7d555db8355"
      },
      "outputs": [],
      "source": [
        "# df_mashup = [''.join(df[['subscriber_id', 'agent_id', 'stage_status']].astype(str).iloc[i].values) for i in range(len(df))]\n",
        "# train_mashup = [''.join(train[['subscriber_id', 'agent_id', 'entry_channel_id', 'stage_status', 'city']].astype(str).iloc[i].values) for i in range(len(train))]\n",
        "# test_mashup = [''.join(test[['subscriber_id', 'agent_id', 'entry_channel_id', 'stage_status', 'city']].astype(str).iloc[i].values) for i in range(len(test))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ed5a7b68-e647-4b10-aec7-1ce38ae013b1",
      "metadata": {
        "id": "ed5a7b68-e647-4b10-aec7-1ce38ae013b1"
      },
      "outputs": [],
      "source": [
        "# df = pd.concat([train, test])\n",
        "# mashup = [''.join(df[['subscriber_id', 'agent_id', 'entry_channel_id', 'stage_status', 'city']].astype(str).iloc[i].values) for i in range(len(df))]\n",
        "# mashup_cleaned = [mashup[i].strip().replace(',','') for i in range(len(mashup))]\n",
        "# CouVec = CountVectorizer()\n",
        "# CouVec.fit(df['agent_id'])\n",
        "\n",
        "# train_words = pd.DataFrame(CouVec.transform(train['agent_id']).toarray())\n",
        "# test_words = pd.DataFrame(CouVec.transform(test['agent_id']).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "540f18ef-1705-4a65-8fef-d70a333a1efa",
      "metadata": {
        "id": "540f18ef-1705-4a65-8fef-d70a333a1efa"
      },
      "outputs": [],
      "source": [
        "# train_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "76d754ac-afc8-4fbe-a6f0-6a35a56ad5a7",
      "metadata": {
        "id": "76d754ac-afc8-4fbe-a6f0-6a35a56ad5a7"
      },
      "outputs": [],
      "source": [
        "# df[['subscriber_id', 'agent_id', 'entry_channel_id', 'stage_status', 'city']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e5e7285d-ccc4-4b60-8353-b630aef07ded",
      "metadata": {
        "id": "e5e7285d-ccc4-4b60-8353-b630aef07ded"
      },
      "outputs": [],
      "source": [
        "# LDA = LatentDirichletAllocation(n_components=15, max_iter=100, random_state=42)\n",
        "# LDA.fit(pd.concat([train_words, test_words]))\n",
        "# Topics = [f'Topic_{x}' for x in range(0,15)]\n",
        "# train[Topics] = LDA.transform(train_words)\n",
        "# test[Topics] = LDA.transform(test_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoder\n",
        "def label_enc(train_df, test_df, features):\n",
        "    lbl_enc = LabelEncoder()\n",
        "    full_data = pd.concat([train_df[features], test_df[features]],axis=0)\n",
        "    for col in (features):\n",
        "        print(col)\n",
        "        lbl_enc.fit(full_data[col].values)\n",
        "        train_df[col] = lbl_enc.transform(train_df[col])\n",
        "        test_df[col] = lbl_enc.transform(test_df[col])\n",
        "    return train_df, test_df\n",
        "\n",
        "train, test = label_enc(train, test, ['subscriber_id', 'agent_id', 'entry_channel_id', 'stage_status', 'city', 'month_day', 'year_month_day'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLT6LzQwenQT",
        "outputId": "5b71f227-d6d7-45bd-d5dd-c9a190cfa88c"
      },
      "id": "sLT6LzQwenQT",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subscriber_id\n",
            "agent_id\n",
            "entry_channel_id\n",
            "stage_status\n",
            "city\n",
            "month_day\n",
            "year_month_day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "2b3b1f7a-cfab-4944-9649-cd54832c9b0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b3b1f7a-cfab-4944-9649-cd54832c9b0c",
        "outputId": "a7842452-eaf4-409b-ad0d-9cbbd592e469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((214847, 15), (92078, 14))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# train.info()\n",
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Duplicated\n",
        "# cols = train.columns\n",
        "# dup = []\n",
        "# for feat_1 in cols:\n",
        "#     if (feat_1 in dup):\n",
        "#         continue\n",
        "#     for feat_2 in cols.drop(feat_1):\n",
        "#         if (feat_2 in dup):\n",
        "#             continue\n",
        "#         if (train[feat_1].equals(train[feat_2])):\n",
        "#             train.drop(feat_2,inplace=True,axis=1)\n",
        "#             test.drop(feat_2,inplace=True,axis=1)\n",
        "#             dup.append(feat_2)"
      ],
      "metadata": {
        "id": "DYC4Zl_Zfrfy"
      },
      "id": "DYC4Zl_Zfrfy",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "#create two different dataframe of majority and minority class\n",
        "df_majority = train[(train['label'] != 'Backlog')]\n",
        "df_minority = train[(train['label'] == 'Backlog')]\n",
        "# upsample minority class\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,    # sample with replacement\n",
        "                                 n_samples= 88, # to match majority class\n",
        "                                 random_state=42)  # reproducible results\n",
        "# Combine majority class with upsampled minority class\n",
        "df = pd.concat([df_minority_upsampled, df_majority])\n",
        "df['label'].value_counts(normalize=True).plot.bar()\n",
        "df['label'].value_counts()\n",
        "df.shape, train.shape"
      ],
      "metadata": {
        "id": "CcizFecjigWD"
      },
      "id": "CcizFecjigWD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.label.value_counts()"
      ],
      "metadata": {
        "id": "4L2x2MYLjH1U"
      },
      "id": "4L2x2MYLjH1U",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.drop('label', axis = 1), df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15, shuffle = True, random_state = random_seed)"
      ],
      "metadata": {
        "id": "3cmix8sygk4k"
      },
      "id": "3cmix8sygk4k",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_train, d_test  = Pool(X_train, y_train), Pool(X_test, y_test)\n",
        "cb_model_ = CatBoostClassifier(l2_leaf_reg = 9.441413522475084, depth = 7, bootstrap_type = 'Bayesian', learning_rate = 0.01772339213540557, n_estimators = 3167, use_best_model = True,\n",
        "                                                 leaf_estimation_iterations = 1, random_strength = 0.17095032711212016, loss_function = 'MultiClass', verbose = 0, random_state = random_seed)\n",
        "cb_model_.fit(d_train, eval_set = [(d_test)], verbose = 0, early_stopping_rounds = 500)\n",
        "preds_ = cb_model_.predict_proba(d_test)\n",
        "log_loss(y_test, preds_).round(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v_j55d1gRzM",
        "outputId": "1d686dba-b829-42df-a8d5-0b16f5717123"
      },
      "id": "5v_j55d1gRzM",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.74341"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model_ = LGBMClassifier(boosting_type = 'gbdt', objective = 'multiclass', metric = 'multi_logloss', n_estimators = 3000, learning_rate = 0.01, use_best_model = True,\n",
        "                                             num_leaves = 45, colsample_bytree = 0.5, subsample = 0.9, subsample_freq = 1, max_depth = 6, reg_alpha = 0.8, reg_lambda = 0.8,\n",
        "                                             min_split_gain = 0.05, min_child_weight = 0.05, random_state = random_seed, num_class = 12, silent = -1, verbose = -1)\n",
        "lgb_model_.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_test, y_test)], early_stopping_rounds = 500, eval_metric = 'logloss', verbose = 0)\n",
        "preds_ = lgb_model_.predict_proba(X_test)\n",
        "log_loss(y_test, preds_).round(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgOIf-pSwU18",
        "outputId": "d6e3be21-f5e5-445f-b71a-e95248cd9ecc"
      },
      "id": "lgOIf-pSwU18",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.73614"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating fols to n=be used for cross validation\n",
        "TARGET_COL = 'label'\n",
        "remove_features = ['label', 'folds']\n",
        "features_columns = [col for col in df.columns if col not in remove_features]\n",
        "cat = le.fit_transform(df.label)\n",
        "def create_folds(data):\n",
        "    data[\"folds\"] = -1\n",
        "    data = data.sample(frac = 1).reset_index(drop = True)\n",
        "    num_bins = np.floor(1 + np.log2(len(train))).astype(int)\n",
        "    data.loc[:, \"bins\"] = pd.cut(cat, bins = num_bins, labels = False)\n",
        "    kf = StratifiedKFold(n_splits = 15)\n",
        "    for f, (t_, v_) in enumerate(kf.split(X = data, y = data.bins.values)):\n",
        "        data.loc[v_, \"folds\"] = f\n",
        "    data.drop(\"bins\", axis = 1, inplace = True)\n",
        "    return data\n",
        "train = create_folds(df)"
      ],
      "metadata": {
        "id": "5_ExpMo0hCmI"
      },
      "id": "5_ExpMo0hCmI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss_score_ = []\n",
        "print(\"-\" * 30)\n",
        "n_splits = 15\n",
        "for fold in range(n_splits):\n",
        "  x_train_, y_train_ = train[train['folds']!=fold][features_columns] , train[train['folds']!=fold][TARGET_COL] \n",
        "  x_test_, y_test_ = train[train['folds']==fold][features_columns] , train[train['folds']==fold][TARGET_COL] \n",
        "  d_train = Pool(x_train_, y_train_)\n",
        "  d_test = Pool(x_test_, y_test_)\n",
        "  model_cb = CatBoostClassifier(l2_leaf_reg = 9.441413522475084, depth = 7, bootstrap_type = 'Bayesian', learning_rate = 0.01772339213540557, n_estimators = 3167, use_best_model = True,\n",
        "                                                 leaf_estimation_iterations = 1, random_strength = 0.17095032711212016, loss_function = 'MultiClass', verbose = 0, random_state = random_seed)\n",
        "  model_cb.fit(d_train, eval_set = [(d_train), (d_test)], verbose = 0, early_stopping_rounds = 500)\n",
        "  preds_ = model_cb.predict_proba(d_test)\n",
        "  log_loss_ = log_loss(y_test_, preds_)\n",
        "  print(f'LOG_LOSS_{fold + 1}: {log_loss_}')\n",
        "  log_loss_score_.append(log_loss_)\n",
        "  print(\"-\" * 30)\n",
        "print('\\n')\n",
        "print(f\"LOG_LOSS_CV_CB: {np.mean(log_loss_score_).round(5)}\")"
      ],
      "metadata": {
        "id": "Dxw_Be8wlxfy"
      },
      "id": "Dxw_Be8wlxfy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss_score_lgb = []\n",
        "print(\"-\" * 30)\n",
        "n_splits = 15\n",
        "for fold in range(n_splits):\n",
        "  x_train_, y_train_ = train[train['folds']!=fold][features_columns] , train[train['folds']!=fold][TARGET_COL] \n",
        "  x_test_, y_test_ = train[train['folds']==fold][features_columns] , train[train['folds']==fold][TARGET_COL] \n",
        "  model_lgb = LGBMClassifier(boosting_type = 'gbdt', objective = 'multiclass', metric = 'multi_logloss', n_estimators = 3000, learning_rate = 0.01, \n",
        "                              num_leaves = 45, colsample_bytree = 0.8, subsample = 0.9, subsample_freq = 1, max_depth = 6, reg_alpha = 0.5, reg_lambda = 0.5, \n",
        "                              min_split_gain = 0.05, min_child_weight = 0.05, random_state = random_seed, num_class = 13, silent = -1, verbose = -1)\n",
        "  model_lgb.fit(x_train_, y_train_, eval_set = [(x_train_, y_train_), (x_test_, y_test_)], early_stopping_rounds = 300, eval_metric = 'logloss', verbose = 0)\n",
        "  preds_ = model_lgb.predict_proba(x_test_)\n",
        "  log_loss_ = log_loss(y_test_, preds_)\n",
        "  print(f'LOG_LOSS_{fold + 1}: {log_loss_}')\n",
        "  log_loss_score_lgb.append(log_loss_)\n",
        "  print(\"-\" * 30)\n",
        "print('\\n')\n",
        "print(f\"LOG_LOSS_CV_LGB: {np.mean(log_loss_score_lgb).round(5)}\")"
      ],
      "metadata": {
        "id": "AnCC763jlwiE"
      },
      "id": "AnCC763jlwiE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_submit(test_, filename):\n",
        "    d_ = {'ID' : ID, 'Activated' : test_[:, 0], 'Awaiting Activation' : test_[:, 1], 'Awaiting Vehicle Pickup' : test_[:, 2], 'Backlog' : test_[:, 3], 'Checked In For Test' : test_[:, 4], 'In Verification' : test_[:, 5],\n",
        "         'Issued Guarantor Form' : test_[:, 6], 'Onboarding' : test_[:, 7], 'Received Guarantor Form' : test_[:, 8], 'Test Scheduled' : test_[:, 9], 'Tested' : test_[:, 10], 'Top of the funnel' : test_[:, 11]}\n",
        "    df_ = pd.DataFrame(data = d_)\n",
        "    df_ = df_[['ID', 'Activated', 'Awaiting Activation', 'Awaiting Vehicle Pickup',\n",
        "       'Backlog', 'Checked In For Test', 'In Verification',\n",
        "       'Issued Guarantor Form', 'Onboarding', 'Received Guarantor Form',\n",
        "       'Test Scheduled', 'Tested', 'Top of the funnel']]\n",
        "    df_.to_csv(f'{filename}.csv', index = False)\n",
        "    return df_.shape"
      ],
      "metadata": {
        "id": "x5qv3F0blwbs"
      },
      "id": "x5qv3F0blwbs",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_a = cb_model_.predict_proba(test)\n",
        "y_b = lgb_model_.predict_proba(test)\n",
        "# y_c = model_cb.predict_proba(test)\n",
        "# y_d = model_lgb.predict_proba(test)"
      ],
      "metadata": {
        "id": "XW65LyaSsxM7"
      },
      "id": "XW65LyaSsxM7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = 0.5 * y_b + 0.5 * y_b\n",
        "pred = y_b+\n",
        "predict_and_submit(pred, 'ai_cat_1.1_')"
      ],
      "metadata": {
        "id": "370i_vNSsdDQ"
      },
      "id": "370i_vNSsdDQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KoxUC5qs21F"
      },
      "id": "_KoxUC5qs21F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}