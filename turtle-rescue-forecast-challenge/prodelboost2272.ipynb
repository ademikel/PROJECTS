{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqw0ohaaURgg",
    "outputId": "3fb443fe-d5c2-4ddf-c1fb-713aa8416452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost==0.20.2\n",
      "  Downloading catboost-0.20.2-cp37-none-manylinux1_x86_64.whl (63.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.9 MB 7.7 kB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (1.21.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (3.2.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (0.10.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (1.15.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (1.4.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost==0.20.2) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost==0.20.2) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost==0.20.2) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost==0.20.2) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost==0.20.2) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost==0.20.2) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost==0.20.2) (4.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost==0.20.2) (8.0.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "Q7Y_NXqZU5zi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO \n",
    "import datetime as dt\n",
    "from catboost import CatBoostRegressor\n",
    "import datetime as dt\n",
    "import re\n",
    "from fastai.tabular import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gg0xaFq8VHJT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "sample_sub = pd.read_csv('Sample_sub.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "cap_cat = pd.read_csv('CaptureSite_category.csv')\n",
    "\n",
    "ss = sample_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5C_NH4O-VLee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to add date features from the fast ai library\n",
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "9AuTVmvPVRq4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Data wrangling to create training and testing datasets\n",
    "sample_sub[\"year_woy\"]=(sample_sub.ID.apply(lambda x: x.split(\"_\")[-1])).astype(int)\n",
    "sample_sub[\"CaptureSite\"]=sample_sub.ID.apply(lambda x: (\"_\").join(x.split(\"_\")[0:-1]))\n",
    "\n",
    "# Create Time features from Date_TimeCaught \n",
    "train[\"Date_TimeCaught\"]=pd.to_datetime(train[\"Date_TimeCaught\"])\n",
    "train[\"year\"]=train.Date_TimeCaught.dt.year\n",
    "train[\"week_of_year\"]=train.Date_TimeCaught.dt.weekofyear\n",
    "train[\"year_woy\"]=train.year*100+train.week_of_year\n",
    "\n",
    "# Concatinating week oy year and capture site in the training dataset to the submission dataset\n",
    "# Grouping the data by capture site and taking the minimum week of year\n",
    "keys=pd.concat([train[[\"year_woy\",\"CaptureSite\"]],sample_sub[[\"year_woy\",\"CaptureSite\"]]])\n",
    "CaptureSite_min_year_woy=keys.groupby(\"CaptureSite\").year_woy.min().rename(\"year_woy\").reset_index()\n",
    "\n",
    "# Creating an empty dataframe and adding the necessary columns\n",
    "# Dropping duplicates\n",
    "range_year_woy=pd.DataFrame()\n",
    "range_year_woy[\"Date_TimeCaught\"]=pd.date_range(start=train.Date_TimeCaught.min(),end='2019/10/31')\n",
    "range_year_woy[\"year\"]=range_year_woy.Date_TimeCaught.dt.year\n",
    "range_year_woy[\"week_of_year\"]=range_year_woy.Date_TimeCaught.dt.weekofyear\n",
    "range_year_woy[\"year_woy\"]=range_year_woy.year*100+range_year_woy.week_of_year\n",
    "range_year_woy.drop_duplicates([\"year_woy\"],inplace=True)\n",
    "\n",
    "# Joining the cleaned datasets together\n",
    "final_data=[]\n",
    "for site , year_woy in zip(CaptureSite_min_year_woy.CaptureSite.values,CaptureSite_min_year_woy.year_woy.values) :\n",
    "\n",
    "    one_site_df=range_year_woy[range_year_woy.year_woy>=year_woy]\n",
    "    one_site_df[\"CaptureSite\"]=site\n",
    "    final_data.append(one_site_df)\n",
    "final_data=pd.concat(final_data)\n",
    "\n",
    "\n",
    "\n",
    "# Extracting the target variable from the dataet\n",
    "Target=train.groupby([\"year_woy\",\"CaptureSite\"]).CaptureSite.count().rename(\"Capture_Number\").reset_index()\n",
    "final_data=final_data.merge(Target,on=[\"year_woy\",\"CaptureSite\"],how=\"left\")\n",
    "final_data.Capture_Number.fillna(0,inplace=True)\n",
    "\n",
    "# Separating the training set and testing set\n",
    "train=final_data[final_data.year<2019]\n",
    "test=final_data[final_data.year==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "_rWUVM3vVdwl",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Combining test and train to create features efficiently\n",
    "target = train.Capture_Number\n",
    "\n",
    "train['separator'] = 0\n",
    "test['separator'] = 1\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "train_test = pd.concat([train, test])\n",
    "train_test.drop(['year',\t'week_of_year', 'Capture_Number'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "jhGry70uVk3y",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding features\n",
    "train_test = train_test.merge(cap_cat, how = 'left', on = 'CaptureSite')\n",
    "train_test['id'] = [x + '_' + str(y) for x, y in zip(train_test.CaptureSite, train_test.year_woy)]\n",
    "\n",
    "# Adding date features using functions from the fast ai library\n",
    "add_datepart(train_test, 'Date_TimeCaught', False)\n",
    "add_cyclic_datepart(train_test, 'Date_TimeCaught')\n",
    "\n",
    "# Creating a list of categorical features\n",
    "categorical_features = ['Date_TimeCaughtMonth',\t'Date_TimeCaughtWeek',\t'Date_TimeCaughtDay',\t'Date_TimeCaughtDayofweek',\\\n",
    "           'CaptureSite', 'CaptureSiteCategory', 'Type']\n",
    "\n",
    "# Converting categorical columns to category datatype\n",
    "for col in categorical_features:\n",
    "  train_test[col] = train_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "id": "YWJlA6QXVp1b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separating the training and testing datasets\n",
    "train = train_test[train_test.separator == 0]\n",
    "test = train_test[train_test.separator == 1]\n",
    "\n",
    "# Dropping the separator column\n",
    "train.drop('separator', axis = 1, inplace = True)\n",
    "test.drop('separator', axis = 1, inplace = True)\n",
    "\n",
    "# Adding target variable to check for correlations\n",
    "train['target'] = list(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "id": "luRkbXyoVttg",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Training and making predictions\n",
    "# Dropping the id and target columns from the training set\n",
    "X = train.drop(['id', 'target'], axis = 1)\n",
    "y = train.target\n",
    "tes = test.drop('id', axis = 1)\n",
    "\n",
    "# Using catboost regressor to train.\n",
    "cat = CatBoostRegressor(logging_level='Silent',cat_features=categorical_features, random_state = 101)\n",
    "cat.fit(X, y)\n",
    "\n",
    "# making predictions and creating a submission file\n",
    "preds = cat.predict(tes)*1.229\n",
    "sub_df = pd.DataFrame({'ID': test.id, 'Captured_Number': preds}) \n",
    "sub_df.to_csv('prodel119.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prodelboost2272.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
