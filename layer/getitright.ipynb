{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "91517d92",
   "metadata": {
    "id": "91517d92"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "449cb28d",
   "metadata": {
    "id": "449cb28d"
   },
   "outputs": [],
   "source": [
    "#Label Encoder\n",
    "def label_enc(train_df, test_df, features):\n",
    "    lbl_enc = LabelEncoder()\n",
    "    full_data = pd.concat([train_df[features], test_df[features]],axis=0)\n",
    "    for col in (features):\n",
    "        print(col)\n",
    "        lbl_enc.fit(full_data[col].values)\n",
    "        train_df[col] = lbl_enc.transform(train_df[col])\n",
    "        test_df[col] = lbl_enc.transform(test_df[col])\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "addd163a",
   "metadata": {
    "id": "addd163a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")\n",
    "sub = pd.read_csv(\"SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "64f3afc8-23ff-4c12-9f19-b1b4692db9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0XbVxngY6vtq",
   "metadata": {
    "id": "0XbVxngY6vtq"
   },
   "outputs": [],
   "source": [
    "col1 = ['ID','date']\n",
    "col2 = ['device']\n",
    "col3 = ['humidity', 'temp_mean']\n",
    "location = ['site_latitude', 'site_longitude']\n",
    "chem = [\n",
    "        'SulphurDioxide_SO2_column_number_density',\n",
    "       'SulphurDioxide_SO2_column_number_density_amf',\n",
    "        'SulphurDioxide_SO2_column_number_density_15km',\n",
    "       'CarbonMonoxide_CO_column_number_density',\n",
    "        'NitrogenDioxide_NO2_column_number_density',\n",
    "        'UvAerosolIndex_absorbing_aerosol_index',\n",
    "        'Ozone_O3_column_number_density',\n",
    "        'Cloud_cloud_fraction', \n",
    "        'Cloud_cloud_top_pressure',\n",
    "]\n",
    "target = ['pm2_5']\n",
    "feat = col1 + col2 + col3 + location + chem\n",
    "train_df = train_df[feat + target]\n",
    "test_df = test_df[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "067db8de-b4d9-4595-9e14-db599bc7bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 17), (4254, 16))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be527b52",
   "metadata": {
    "id": "be527b52"
   },
   "source": [
    "# Add The Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4386282b",
   "metadata": {
    "id": "4386282b"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(['date', 'device']).reset_index(drop=True) \n",
    "test_df = test_df.sort_values(['date', 'device']).reset_index(drop=True)\n",
    "\n",
    "for dataset in (train_df,test_df):\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset['Day'] = dataset.date.dt.day\n",
    "    dataset['Month'] = dataset.date.dt.month\n",
    "    dataset['Year'] = dataset.date.dt.year\n",
    "    dataset['DayOfWeek'] = dataset.date.dt.dayofweek\n",
    "    dataset['DayOfYear'] = dataset.date.dt.dayofyear\n",
    "    dataset['Week'] = dataset.date.dt.weekofyear\n",
    "    dataset.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c5f92c3a",
   "metadata": {
    "id": "c5f92c3a"
   },
   "outputs": [],
   "source": [
    "ID = test_df['ID']\n",
    "test_df.drop('ID',inplace=True,axis=1)\n",
    "train_df.drop('ID',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53857f36",
   "metadata": {
    "id": "53857f36"
   },
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9783ebdf",
   "metadata": {
    "id": "9783ebdf"
   },
   "outputs": [],
   "source": [
    "num_col = train_df.select_dtypes(exclude='O').columns.difference(['Month', 'pm2_5', 'site_latitude', 'site_longitude', 'humidity', 'temp_mean', 'Day', 'DayOfWeek', 'DayOfYear', 'Year', 'Week'])\n",
    "train_df.temp_mean = train_df.temp_mean.fillna(train_df.temp_mean.median())\n",
    "for data in (train_df, test_df):\n",
    "    for feat in num_col:\n",
    "        data[feat] = data[feat].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "37916f9d",
   "metadata": {
    "id": "37916f9d"
   },
   "outputs": [],
   "source": [
    "def LAG(data,LagFeature,shift=1,NewFeatures=[]) :\n",
    "    data[NewFeatures[0]]   = data[LagFeature]  - data[LagFeature].shift(shift)\n",
    "    data[NewFeatures[1]]   = data[LagFeature].shift(shift)\n",
    "\n",
    "num_feats = train_df.columns\n",
    "num_feats = num_feats.drop(['DayOfWeek','Month','Day','pm2_5','temp_mean','humidity','site_longitude', 'site_latitude','device', 'Year', 'DayOfYear', 'Week'])\n",
    "\n",
    "for feature in num_feats:\n",
    "    LAG(train_df,LagFeature=f'{feature}',shift=1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])\n",
    "    LAG(test_df,LagFeature=f'{feature}',shift=1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5cba07fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cba07fe",
    "outputId": "369653f4-d709-4a9e-a05c-75a4fbde3f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_Week\n",
      "Month_Day\n",
      "device\n",
      "lat_lon\n"
     ]
    }
   ],
   "source": [
    "for dataset in (train_df,test_df):\n",
    "    dataset['Year_Week'] = dataset['Year'].astype(str) + '-' + dataset['Week'].astype(str)\n",
    "    dataset['Month_Day'] = dataset['Month'].astype(str) + '-' + dataset['Day'].astype(str)\n",
    "    dataset['lat_lon'] = dataset['site_latitude'].astype(str) + '_' + dataset['site_longitude'].astype(str)\n",
    "    \n",
    "feats = ['Year_Week','Month_Day', 'device',\n",
    "         'lat_lon'\n",
    "        ]\n",
    "train_df,test_df = label_enc(train_df,test_df,feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "928f7013-6a65-4cc6-ad9a-a457ab900d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4254, 41), (9923, 42))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ba255c96",
   "metadata": {
    "id": "ba255c96"
   },
   "outputs": [],
   "source": [
    "DevicePM2_5Mean = dict(train_df.groupby('device')['pm2_5'].mean())\n",
    "DevicePM2_5Std = dict(train_df.groupby('device')['pm2_5'].std())\n",
    "DevicePM2_5Min = dict(train_df.groupby('device')['pm2_5'].min())\n",
    "DevicePM2_5Max = dict(train_df.groupby('device')['pm2_5'].max())\n",
    "\n",
    "for dataset in (train_df,test_df):\n",
    "    dataset['DevicePM2_5Mean'] = dataset['device'].map(DevicePM2_5Mean)\n",
    "    dataset['DevicePM2_5Std'] = dataset['device'].map(DevicePM2_5Std)\n",
    "    dataset['DevicePM2_5Min'] = dataset['device'].map(DevicePM2_5Min)\n",
    "    dataset['DevicePM2_5Max'] = dataset['device'].map(DevicePM2_5Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e2683617",
   "metadata": {
    "id": "e2683617"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_df, test_df], axis = 0)\n",
    "def Agg(Features):\n",
    "    for dataset in (train_df,test_df):\n",
    "        for Feature in Features:\n",
    "            dataset[f'{Feature}_PerMonth'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].mean()))\n",
    "            dataset[f'{Feature}_PerWeek'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].mean()))\n",
    "            dataset[f'{Feature}_PerDay'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].mean()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_std'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].std()))\n",
    "            dataset[f'{Feature}_Week_std'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].std()))\n",
    "            dataset[f'{Feature}_Day_std'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].std()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_min'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].min()))\n",
    "            dataset[f'{Feature}_Week_min'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].min()))\n",
    "            dataset[f'{Feature}_Day_min'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].min()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_max'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].max()))\n",
    "            dataset[f'{Feature}_Week_max'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].max()))\n",
    "            dataset[f'{Feature}_Day_max'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].max()))\n",
    "        \n",
    "Agg(['temp_mean', 'humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c8521e5e-95a5-433a-a578-5cffc50b5851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 70), (4254, 69))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6acdf188-2a25-4833-811c-05b412e3c7b9",
   "metadata": {
    "id": "6acdf188-2a25-4833-811c-05b412e3c7b9"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7ac33089-3f9a-4395-93a1-e4fbfd7935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(random_state = 101, n_components = 3)\n",
    "# full_data = pd.concat([train_df[chem], test_df[chem]],axis=0)\n",
    "# pca.fit(full_data)\n",
    "# train_df[['pca_1', 'pca_2', 'pca_3']] = pca.transform(train_df[chem])\n",
    "# test_df[['pca_1', 'pca_2', 'pca_3']] = pca.transform(test_df[chem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1bd36e4e",
   "metadata": {
    "id": "1bd36e4e"
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Year_Week', 'Month_Day', 'site_longitude', 'site_latitude'], inplace=True, axis=1)\n",
    "test_df.drop(['Year_Week', 'Month_Day', 'site_longitude', 'site_latitude'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4f333251-d7d1-4c4f-a073-0e33bfe789f7",
   "metadata": {
    "id": "4f333251-d7d1-4c4f-a073-0e33bfe789f7"
   },
   "outputs": [],
   "source": [
    "# corr_matrix = train_df.corr().abs()\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
    "# drop = train_df.corr()['pm2_5'].abs()[train_df.corr()['pm2_5'].abs() < 0.03].index.to_list()\n",
    "# drop_to_drop = [value for value in to_drop if value in drop]\n",
    "# len(drop_to_drop), len(drop), len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4c001f66-af86-4fad-8c09-33b492f96507",
   "metadata": {
    "id": "4c001f66-af86-4fad-8c09-33b492f96507"
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.drop(columns = drop)\n",
    "# test_df = test_df.drop(columns = drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2a66ab46-41b7-47e7-af56-f4ce561f7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.corr()['pm2_5'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c797fd7",
   "metadata": {
    "id": "5c797fd7"
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "FcGRdk9yuQnQ",
   "metadata": {
    "id": "FcGRdk9yuQnQ"
   },
   "outputs": [],
   "source": [
    "#Averaging the predictions of the same model with different seeds to get more consistent results\n",
    "X = train_df.drop('pm2_5', axis = 1)\n",
    "y = train_df.pm2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a",
    "outputId": "8891a97d-2e47-4ac7-9aa2-fe9a78be6017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 66), (9923,), (4254, 66))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac",
   "metadata": {
    "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52efdb8",
   "metadata": {
    "id": "e52efdb8"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b37e0907-2b4c-4c39-be17-394885013e9e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b37e0907-2b4c-4c39-be17-394885013e9e",
    "outputId": "2fb8fae7-01b7-42a0-ef10-cd510152a399",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.359957273962703"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(n_estimators = 6864, learning_rate = 0.028926897706232692, depth = 8, verbose = 0, random_state = 42)\n",
    "model = TransformedTargetRegressor(cb, func = np.log1p, inverse_func = np.expm1)\n",
    "model.fit(X_train, y_train)\n",
    "pred_ = model.predict(X_test)\n",
    "mae(y_test, pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c04114b3-379d-429d-9fa0-b21f1992dc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.604118446326883"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBRegressor(objective = 'reg:squarederror', eval_metric = 'mae', n_estimators = 3800, max_depth = 8, learning_rate = 0.0174)\n",
    "model_1 = TransformedTargetRegressor(xg, func = np.log1p, inverse_func = np.expm1)\n",
    "model_1.fit(X_train, y_train)\n",
    "pred__ = model_1.predict(X_test)\n",
    "mae(y_test, pred__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a0fefe5-e951-4f69-8999-bbdd3ff26877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.238088767321361"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_*0.755 + pred__*0.241018734\n",
    "mae(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13f4d2ae-861f-42fd-a0d9-520c94122c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = KFold(n_splits=10, shuffle = True, random_state = 0)\n",
    "# cv_scores = []\n",
    "# print(\"-\" * 25)\n",
    "# for fold, (tr_in, te_in) in enumerate(ts.split(X)):\n",
    "#     x_train, x_test = X.iloc[tr_in], X.iloc[te_in]\n",
    "#     y_train, y_test = y.iloc[tr_in], y.iloc[te_in]\n",
    "#     LogCB = TransformedTargetRegressor(cb, func = np.log1p, inverse_func = np.expm1)  \n",
    "#     LogCB.fit(x_train, y_train)\n",
    "#     preds = LogCB.predict(x_test)\n",
    "#     error = mae(y_test, preds)\n",
    "#     print(f'MAE_{fold + 1}: {error}')\n",
    "#     cv_scores.append(error)\n",
    "#     print(\"-\" * 25)\n",
    "    \n",
    "# print('\\n')\n",
    "# rint(f\"MAE_CV: {np.mean(cv_scores).round(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "G-nWuS2Hj987",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "G-nWuS2Hj987",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_M1T3S50WVB</td>\n",
       "      <td>70.491377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_S9OZLWWLTX</td>\n",
       "      <td>67.705130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_OC21YTIKX2</td>\n",
       "      <td>74.913201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_BNZBP8KDYD</td>\n",
       "      <td>78.462212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_ZS2RAN8HZT</td>\n",
       "      <td>68.790341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_HSJA8I0X66</td>\n",
       "      <td>83.644648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_3O2ZUT59OO</td>\n",
       "      <td>68.989221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_LWMVVRDK4P</td>\n",
       "      <td>69.160897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_JGEEJ9J0G7</td>\n",
       "      <td>73.602784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_U9UG6FQVPU</td>\n",
       "      <td>46.404610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id      pm2_5\n",
       "date                                \n",
       "2020-08-20  ID_M1T3S50WVB  70.491377\n",
       "2020-08-20  ID_S9OZLWWLTX  67.705130\n",
       "2020-08-20  ID_OC21YTIKX2  74.913201\n",
       "2020-08-20  ID_BNZBP8KDYD  78.462212\n",
       "2020-08-20  ID_ZS2RAN8HZT  68.790341\n",
       "2020-08-20  ID_HSJA8I0X66  83.644648\n",
       "2020-08-20  ID_3O2ZUT59OO  68.989221\n",
       "2020-08-20  ID_LWMVVRDK4P  69.160897\n",
       "2020-08-20  ID_JGEEJ9J0G7  73.602784\n",
       "2020-08-20  ID_U9UG6FQVPU  46.404610"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_df)\n",
    "submission = pd.DataFrame({\"Id\": ID ,\"pm2_5\": pred})\n",
    "submission.to_csv('air_ai_squad.csv', index = False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f766ef-6a52-48b4-a5ed-c272bafced46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
