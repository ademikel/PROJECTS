{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91517d92",
   "metadata": {
    "id": "91517d92"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "449cb28d",
   "metadata": {
    "id": "449cb28d"
   },
   "outputs": [],
   "source": [
    "#Label Encoder\n",
    "def label_enc(train_df, test_df, features):\n",
    "    lbl_enc = LabelEncoder()\n",
    "    full_data = pd.concat([train_df[features], test_df[features]],axis=0)\n",
    "    for col in (features):\n",
    "        print(col)\n",
    "        lbl_enc.fit(full_data[col].values)\n",
    "        train_df[col] = lbl_enc.transform(train_df[col])\n",
    "        test_df[col] = lbl_enc.transform(test_df[col])\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "addd163a",
   "metadata": {
    "id": "addd163a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")\n",
    "sub = pd.read_csv(\"SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0dcc3473-ba0c-40d9-97b4-613dcac5251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns[train_df.columns.str.find('cloud') > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0259ed6d-a86b-452b-a051-3ac70a633f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.corr()['pm2_5'][train_df.corr()['pm2_5'] > 0.1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "0XbVxngY6vtq",
   "metadata": {
    "id": "0XbVxngY6vtq"
   },
   "outputs": [],
   "source": [
    "col1 = ['ID','date']\n",
    "col2 = ['device']\n",
    "col3 = ['humidity', 'temp_mean']\n",
    "location = ['site_latitude', 'site_longitude']\n",
    "chem = ['SulphurDioxide_SO2_column_number_density',\n",
    "        'SulphurDioxide_SO2_column_number_density_amf',\n",
    "        'SulphurDioxide_SO2_column_number_density_15km',\n",
    "        'CarbonMonoxide_CO_column_number_density',\n",
    "        'NitrogenDioxide_NO2_column_number_density',\n",
    "        'UvAerosolIndex_absorbing_aerosol_index',\n",
    "        'Ozone_O3_column_number_density',\n",
    "        'Cloud_cloud_fraction', \n",
    "        'Cloud_cloud_top_pressure']\n",
    "target = ['pm2_5']\n",
    "feat = col1 + col2 + col3 + location + chem\n",
    "train_df = train_df[feat + target]\n",
    "test_df = test_df[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "067db8de-b4d9-4595-9e14-db599bc7bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 17), (4254, 16))"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be527b52",
   "metadata": {
    "id": "be527b52"
   },
   "source": [
    "# Add The Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "4386282b",
   "metadata": {
    "id": "4386282b"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(['date', 'device']).reset_index(drop=True) \n",
    "test_df = test_df.sort_values(['date', 'device']).reset_index(drop=True)\n",
    "\n",
    "for dataset in (train_df,test_df):\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset['Day'] = dataset.date.dt.day\n",
    "    dataset['Month'] = dataset.date.dt.month\n",
    "    dataset['Year'] = dataset.date.dt.year\n",
    "    dataset['DayOfWeek'] = dataset.date.dt.dayofweek\n",
    "    dataset['DayOfYear'] = dataset.date.dt.dayofyear\n",
    "    dataset['Week'] = dataset.date.dt.weekofyear\n",
    "    dataset.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c5f92c3a",
   "metadata": {
    "id": "c5f92c3a"
   },
   "outputs": [],
   "source": [
    "ID = test_df['ID']\n",
    "test_df.drop('ID',inplace=True,axis=1)\n",
    "train_df.drop('ID',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53857f36",
   "metadata": {
    "id": "53857f36"
   },
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9783ebdf",
   "metadata": {
    "id": "9783ebdf"
   },
   "outputs": [],
   "source": [
    "num_col = train_df.select_dtypes(exclude='O').columns.difference(['Month', 'pm2_5', 'site_latitude', 'site_longitude', 'humidity', 'temp_mean', 'Day', 'DayOfWeek', 'DayOfYear', 'Year', 'Week'])\n",
    "train_df.temp_mean = train_df.temp_mean.fillna(train_df.temp_mean.median())\n",
    "for data in (train_df, test_df):\n",
    "    for feat in num_col:\n",
    "        data[feat] = data[feat].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "37916f9d",
   "metadata": {
    "id": "37916f9d"
   },
   "outputs": [],
   "source": [
    "def LAG(data,LagFeature,shift=1,NewFeatures=[]) :\n",
    "    data[NewFeatures[0]]   = data[LagFeature]  - data[LagFeature].shift(shift)\n",
    "    data[NewFeatures[1]]   = data[LagFeature].shift(shift)\n",
    "\n",
    "num_feats = train_df.columns\n",
    "num_feats = num_feats.drop(['DayOfWeek','Month','Day','pm2_5','temp_mean','humidity','site_longitude', 'site_latitude','device', 'Year', 'DayOfYear', 'Week'])\n",
    "\n",
    "for feature in num_feats:\n",
    "    LAG(train_df,LagFeature=f'{feature}',shift=-1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])\n",
    "    LAG(test_df,LagFeature=f'{feature}',shift=1,NewFeatures=[f'{feature}_diff_Lag1',f'{feature}_Lag1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "5cba07fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cba07fe",
    "outputId": "369653f4-d709-4a9e-a05c-75a4fbde3f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_Week\n",
      "Month_Day\n",
      "device\n"
     ]
    }
   ],
   "source": [
    "for dataset in (train_df,test_df):\n",
    "    dataset['Year_Week'] = dataset['Year'].astype(str) + '-' + dataset['Week'].astype(str)\n",
    "    dataset['Month_Day'] = dataset['Month'].astype(str) + '-' + dataset['Day'].astype(str)\n",
    "    # dataset['lat_lon'] = dataset['site_latitude'].astype(str) + '_' + dataset['site_longitude'].astype(str)\n",
    "    \n",
    "feats = ['Year_Week','Month_Day', 'device']\n",
    "train_df,test_df = label_enc(train_df,test_df,feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "928f7013-6a65-4cc6-ad9a-a457ab900d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4254, 40), (9923, 41))"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099d339",
   "metadata": {
    "id": "6099d339"
   },
   "source": [
    "## - Aggregations Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ba255c96",
   "metadata": {
    "id": "ba255c96"
   },
   "outputs": [],
   "source": [
    "DevicePM2_5Mean = dict(train_df.groupby('device')['pm2_5'].mean())\n",
    "DevicePM2_5Std = dict(train_df.groupby('device')['pm2_5'].std())\n",
    "DevicePM2_5Min = dict(train_df.groupby('device')['pm2_5'].min())\n",
    "DevicePM2_5Max = dict(train_df.groupby('device')['pm2_5'].max())\n",
    "\n",
    "for dataset in (train_df,test_df):\n",
    "    dataset['DevicePM2_5Mean'] = dataset['device'].map(DevicePM2_5Mean)\n",
    "    dataset['DevicePM2_5Std'] = dataset['device'].map(DevicePM2_5Std)\n",
    "    dataset['DevicePM2_5Min'] = dataset['device'].map(DevicePM2_5Min)\n",
    "    dataset['DevicePM2_5Max'] = dataset['device'].map(DevicePM2_5Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "e2683617",
   "metadata": {
    "id": "e2683617"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_df, test_df], axis = 0)\n",
    "def Agg(Features):\n",
    "    for dataset in (train_df,test_df):\n",
    "        for Feature in Features:\n",
    "            dataset[f'{Feature}_PerMonth'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].mean()))\n",
    "            dataset[f'{Feature}_PerWeek'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].mean()))\n",
    "            dataset[f'{Feature}_PerDay'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].mean()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_std'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].std()))\n",
    "            dataset[f'{Feature}_Week_std'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].std()))\n",
    "            dataset[f'{Feature}_Day_std'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].std()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_min'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].min()))\n",
    "            dataset[f'{Feature}_Week_min'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].min()))\n",
    "            dataset[f'{Feature}_Day_min'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].min()))\n",
    "\n",
    "            dataset[f'{Feature}_Month_max'] = dataset['Month'].map(dict(data.groupby('Month')[Feature].max()))\n",
    "            dataset[f'{Feature}_Week_max'] = dataset['Year_Week'].map(dict(data.groupby('Year_Week')[Feature].max()))\n",
    "            dataset[f'{Feature}_Day_max'] = dataset['Month_Day'].map(dict(data.groupby('Month_Day')[Feature].max()))\n",
    "        \n",
    "Agg(['temp_mean', 'humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "c8521e5e-95a5-433a-a578-5cffc50b5851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 69), (4254, 68))"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "6acdf188-2a25-4833-811c-05b412e3c7b9",
   "metadata": {
    "id": "6acdf188-2a25-4833-811c-05b412e3c7b9"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7ac33089-3f9a-4395-93a1-e4fbfd7935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(random_state = 101, n_components = 3)\n",
    "# full_data = pd.concat([train_df[chem], test_df[chem]],axis=0)\n",
    "# pca.fit(full_data)\n",
    "# train_df[['pca_1', 'pca_2', 'pca_3']] = pca.transform(train_df[chem])\n",
    "# test_df[['pca_1', 'pca_2', 'pca_3']] = pca.transform(test_df[chem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4f333251-d7d1-4c4f-a073-0e33bfe789f7",
   "metadata": {
    "id": "4f333251-d7d1-4c4f-a073-0e33bfe789f7"
   },
   "outputs": [],
   "source": [
    "# corr_matrix = train_df.corr().abs()\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
    "# drop = train_df.corr()['pm2_5'].abs()[train_df.corr()['pm2_5'].abs() < 0.03].index.to_list()\n",
    "# drop_to_drop = [value for value in to_drop if value in drop]\n",
    "# len(drop_to_drop), len(drop), len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "4c001f66-af86-4fad-8c09-33b492f96507",
   "metadata": {
    "id": "4c001f66-af86-4fad-8c09-33b492f96507"
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.drop(columns = drop)\n",
    "# test_df = test_df.drop(columns = drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "2a66ab46-41b7-47e7-af56-f4ce561f7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.corr()['pm2_5'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1bd36e4e",
   "metadata": {
    "id": "1bd36e4e"
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Year_Week', 'Month_Day', 'site_longitude', 'site_latitude'],inplace=True,axis=1)\n",
    "test_df.drop(['Year_Week', 'Month_Day', 'site_longitude', 'site_latitude'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c797fd7",
   "metadata": {
    "id": "5c797fd7"
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "FcGRdk9yuQnQ",
   "metadata": {
    "id": "FcGRdk9yuQnQ"
   },
   "outputs": [],
   "source": [
    "#Averaging the predictions of the same model with different seeds to get more consistent results\n",
    "X = train_df.drop('pm2_5', axis = 1)\n",
    "y = train_df.pm2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aa897e6-4125-4e58-9d2d-87bf91a0ba1a",
    "outputId": "8891a97d-2e47-4ac7-9aa2-fe9a78be6017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9923, 64), (9923,), (4254, 64))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac",
   "metadata": {
    "id": "ecadbfdc-ee52-430d-b865-ba8e518fc0ac"
   },
   "outputs": [],
   "source": [
    "# X_train, y_train = X[:9000], y[:9000]\n",
    "# X_test, y_test = X[9000:], y[9000:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52efdb8",
   "metadata": {
    "id": "e52efdb8"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "a828c34d-898f-4979-99a0-27c3050f2140",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b37e0907-2b4c-4c39-be17-394885013e9e",
    "outputId": "2fb8fae7-01b7-42a0-ef10-cd510152a399",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.209303976965303"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(n_estimators = 6864, learning_rate = 0.028926897706232692, depth = 8, verbose = 0, random_state = 42)\n",
    "model = TransformedTargetRegressor(cb, func = np.log1p, inverse_func = np.expm1)\n",
    "model.fit(X_train, y_train)\n",
    "pred_1 = model.predict(X_test)\n",
    "mae(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "31cddfc0-cf9a-4946-aee8-4e8f3ecee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg = XGBRegressor(objective = 'reg:squarederror', eval_metric = 'mae', n_estimators = 6000, max_depth = 8, learning_rate = 0.02484, max_leaves = 200, random_state = 42)\n",
    "# model_ = TransformedTargetRegressor(xg, func = np.log1p, inverse_func = np.expm1)\n",
    "# model_.fit(X_train, y_train)\n",
    "# pred_2 = model_.predict(X_test)\n",
    "# mae(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "G-nWuS2Hj987",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "G-nWuS2Hj987",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_M1T3S50WVB</td>\n",
       "      <td>67.975422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_S9OZLWWLTX</td>\n",
       "      <td>65.308804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_OC21YTIKX2</td>\n",
       "      <td>73.866973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_BNZBP8KDYD</td>\n",
       "      <td>79.361904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>ID_ZS2RAN8HZT</td>\n",
       "      <td>64.582965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id      pm2_5\n",
       "date                                \n",
       "2020-08-20  ID_M1T3S50WVB  67.975422\n",
       "2020-08-20  ID_S9OZLWWLTX  65.308804\n",
       "2020-08-20  ID_OC21YTIKX2  73.866973\n",
       "2020-08-20  ID_BNZBP8KDYD  79.361904\n",
       "2020-08-20  ID_ZS2RAN8HZT  64.582965"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_df)\n",
    "submission = pd.DataFrame({\"Id\": ID ,\"pm2_5\": pred})\n",
    "submission.to_csv('drip__.csv', index = False)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f766ef-6a52-48b4-a5ed-c272bafced46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
